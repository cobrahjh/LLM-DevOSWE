# LLM-DevOSWE Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# REQUIRED
# ===========================================

# Anthropic API Key (for Claude integration)
ANTHROPIC_API_KEY=sk-ant-api03-your-key-here

# ===========================================
# OPTIONAL - LLM Backend
# ===========================================

# LLM backend: 'ollama', 'lmstudio', or 'auto'
LLM_BACKEND=lmstudio

# Ollama URL (local LLM)
OLLAMA_URL=http://localhost:11434

# LM Studio URL (local LLM with OpenAI-compatible API)
LMSTUDIO_URL=http://localhost:1234

# ===========================================
# OPTIONAL - Security
# ===========================================

# API key for relay authentication (leave empty for localhost bypass)
HIVE_API_KEY=

# Enable SSL/HTTPS
SSL_ENABLED=false

# ===========================================
# OPTIONAL - Network
# ===========================================

# Primary relay URL (for multi-machine setups)
PRIMARY_RELAY=http://localhost:8600

# Node name (for multi-machine identification)
NODE_NAME=commander-pc

# ===========================================
# OPTIONAL - Development
# ===========================================

# Node environment
NODE_ENV=development

# Debug logging
DEBUG=false
